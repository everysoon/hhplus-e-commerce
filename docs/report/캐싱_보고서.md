# 인기 상품 날짜별 캐싱 전략 보고서

## 1. 배경

이커머스 서비스에서 "인기 상품" 목록은 사용자 진입 시 가장 많이 접근되는 핵심 데이터라고 생각하고,
제가 구현한 시나리오에서는 날짜 와 개수(`startDate`,`endDate`,`topN`)를 토대로
해당 날짜기간 동안 몇 개의 인기상품 리스트를 조회할 것인지를 API로 제공하고 있습니다.

해당 인기상품 데이터는 다음과 같은 특성을 가집니다

- 조회 빈도는 높지만 갱신 빈도는 낮음 (주로 증가/감소 처리)

- 시간 구간(날짜)별 통계적 의미가 있음

- 실시간 동기화보다 빠른 응답이 중요함

이러한 특성은 캐싱을 적용하여 시스템 부하를 줄이고 사용자 응답 속도를 향상시키기 위해 인기상품에 redis 캐싱을 적용하면서 겪었던 내용을 보고서로 작성하려 합니다.

## 2. 문제 정의 및 해결 전략

### 문제

- 인기 상품 순위는 Redis Sorted Set(ZSet)으로 일별 보관됨

- 트래픽 급증 시 인기 상품 목록을 조회하는 쿼리로 인해 RDB 부하 발생

- 정렬, 그룹화, 통계 연산은 RDB에서 비용이 높음

### 해결 전략

- 캐싱 전략으로 Look-Aside Cache 패턴을 채택

- 날짜별 키(popular:products:yyyy-MM-dd)로 인기 상품 목록을 Redis에 저장

- 캐시 미스 시 DB 조회 후 캐시에 저장 (TTL 포함)

- RedisTemplate 기반으로 Repository 인터페이스에 의존하지 않는 방식 구현하려 노력

## 3. 캐시 적용 구간 및 쿼리 분석

### 시나리오 1: 사용자 진입 시 인기 상품 목록 조회

해당 쿼리는 다음과 같습니다.

````
SELECT p.id, COUNT(p.*) FROM products
JOIN order_items oi ON p.id = oi.product_id
JOIN order o ON o.id = oi.order_id
WHERE o.ordered_at BETWEEN :startDate AND :endDate
GROUP BY p.id
ORDER BY COUNT(oi.quantity) DESC
LIMIT :topN
````

- 지연 발생 가능성 높음

- ✅ 캐시 가능 (날짜별, Top-N 결과 고정)

### 시나리오 2: 상품 주문 시 인기 상품 점수 증가

쿼리 없음 (Redis에서 score 증가)

- ✅ 즉시 반영 (캐시 갱신만)

## 4. 캐시 적용 위치 및 이유

- 도메인 계층은 비즈니스 로직과 정책을 담당하므로, 캐시 로직이 포함되면 관심사가 분산됨

- Repository 계층은 데이터 저장소 접근의 추상화 계층이므로 캐시 조회/저장을 포함하는 것이 자연스러움

- ✅ 따라서, 캐싱 로직은 PopularProductRepository 내부에 구현함

## 5. 직렬화/역직렬화 전략

- Redis에 객체 저장 시 JSON 직렬화 사용

- JsonJacksonCodec으로 직렬화/역직렬화 처리

- 예외 발생 시 fallback 또는 로그 저장 및 예외 리턴 전략 적용

## 6. 테스트

- Embedded Redis 환경을 활용해 통합 테스트 수행

- 캐시 Hit/Miss 여부, TTL 만료 후 재조회, 직렬화 실패 등 예외 처리까지 검증

## 7. 한계점 및 개선 방향

1. TTL 기반 전략으로 실시간성 보장은 어려움 → Pub/Sub 연동 고려

2. ZSet으로 직접 순위 저장 시 범위 조회 가능하나, 복잡도 증가

3. 캐시 직렬화 에러 발생 시 fallback 처리 외 복구 전략은 미흡

4. 캐시 업데이트와 DB 동기화 사이의 eventual consistency 허용 필요

## 8. 결론

Look-Aside 캐싱 전략을 통해 인기 상품 조회 시의 부하를 효과적으로 줄이고, 조회 성능을 개선할 수 있었습니다. 
단, TTL 및 consistency 문제는 트레이드오프가 존재하며, 이에 대한 적절한 조정 및 운영 모니터링이 필요합니다.
캐싱은 도메인이 아닌 저장소 관점의 책임이므로 Repository 계층에서 관리하며, 직렬화 오류는 JSON 기반으로 처리하고 예외 발생 시 시스템 전체 오류로 이어지지 않도록 안전하게 처리했습니다.



