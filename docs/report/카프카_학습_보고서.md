# 카프카 기초 학습에 대한 보고서 

## 1. 배경
Apache Kafka는 높은 확장성과 내결함성을 가진 분산 스트리밍 플랫폼으로, 다수의 producer와 consumer가 동시에 메시지를 송수신하면서도 순서 보장, 내구성, 병렬 처리, 재처리(replay) 등을 제공하는 강력한 메시징 시스템입니다.
이 보고서는 Kafka의 핵심 구성 요소를 명확히 설명하고, producer, partition, consumer 수 변화에 따른 데이터 흐름을 분석하여 효율적인 Kafka 설계와 최적화 방안을 이해하는 데 도움을 주고자 작성되었습니다.

## 2. 기본 개념 
### (1) Broker
- Kafka 클러스터를 구성하는 서버 노드
- 하나의 Kafka 클러스터는 여러 개의 Broker로 구성되고 각 Broker는 특정 파티션 데이터를 저장하고 해당 파티션의 리더/팔로워 역할을 맡음
- Broker는 Partition 리더-팔로워 간 복제 관리를 담당.
  - Kafka에서 Partition은 리더와 팔로워 복제본(replication factor)으로 관리된다. 하나의 Partition 데이터를 여러 Broker에 복제본으로 유지.
  - 리더 Broker가 다운되면 팔로워 중 하나를 리더로 승격하므로 장애가 발생해도 데이터 유실 없이 서비스를 지속할 수 있게 내결합성을 높인다.
  - 리더가 팔로워에 Commit(ack)된 메세지만 "쓰기 완료"로 간주`(ISR:In-Sync-Replicas,리더와 팔로우 파티션이 모두 동기화 된 상태)`하므로 데이터 안정성을 도모할 수 있음.
  - Broker 일부 장애에도 클러스터 전체가 정상 동작하므로 고가용성을 야기할 수 있음.
### (2) Topic
- Kafka에서 데이터가 저장되는 논리적 공간(버킷)
- Producer는 Topic으로 메세지를 전송하고, Consumer는 Topic에서 메세지를 소비함.
- 하나의 Topic은 여러 개의 Partition으로 나뉘어 관리되고 Append-Only Log 구조로 데이터를 순차적으로 저장한다.(바뀌지 않은 로그 파일에 쌓임)
  - log 구조 덕분에 offset 기반으로 "어디까지 읽었는가"만 추적하면 되고, 디스크도 순차 쓰기에 최적화.
  - 일정 기간(retention.ms)이나 크기(retention.bytes)를 기준으로 오래된 데이터는 자동 삭제.
### (3) Offset
- Partition 내의 각 메세지를 고유하게 식별하는 순차적인 번호
- Consumer는 Current-Offset을 기억하고 어디까지 읽었는지 추적하므로 메세지를 중복,유실처리하지 않고 장애 후 복구가 가능하다.
- Kafka는 consumer group별로 offset을 내부 topic __consumer_offsets에 저장
  - Offset 관리 방식:
    - Auto Commit: Kafka 클라이언트가 주기적으로 자동 commit.
    - Manual Commit: 애플리케이션에서 메시지 처리 후 명시적으로 commit.
    - Auto-Commit은 편하지만 처리 실패 시 이미 Commit된 Offset 때문에 메세지 유실 위험이 있고, Manual-Commit은 성공 처리된 메세지만 Offset을 Commit하므로 상대적으로 더 안전하다. 
### (4) Partition
- Topic을 물리적으로 나눈 단위, 각 Partition은 Broker에 분산되어 저장된다.
- Partition은 독립적인 처리 단위로 별도의 Broker, Consumer에서 병렬처리가 가능하다
- **Partition 내에서의 메세지는 순서보장이 가능하다.**
- Partition의 수를 늘리면 더 많은 Broker에 분산되므로 클러스터 확장이 가능하고 더 많은 Consumer가 병렬로 처리하므로 처리량이 증가한다.
### (5) Producer
- 메시지를 생성해 Kafka 클러스터로 전송하는 역할
- key-value 형태의 메세지를 Topic으로 전송
- Partitioner의 분배 전략을 통해 어느 Partition으로 메세지를 넣을지 결정
  - 메세지가 키가 존재 : hash(key) % partition 개수 → 같은 key는 항상 같은 partition.
  - 메세지가 키가 없음 : round-robin, sticky, custom 등으로 분배 (default : sticky)
    - round-robin : 메세지에 Key가 없는 경우, 각 Partition에 순서대로 번갈아 가며 메세지를 보냄.(균등한 분배)
    - sticky : 비슷한 레코드를 같은 Partition으로 묶어 배치 성능 최적화, 배치 전송이 발생하거나 레코드 전송이 실패하면 다음 Partition으로 변경하는 방법 
    - custom : 사용자가 직접 구현한 Partitioner 클래스 이용, custom한 로직으로 Partition을 결정. 
  - Partitioner의 분배 전략에 따라 메세지 순서 보장 범위가 달라지고`(같은 Key-> 같은 Partition-> 순서 보장)`, 전체 처리 부하 분산 효율이 달라진다. 
### (6) Consumer
- Kafka에서 데이터를 읽는 쪽, 특정 Topic의 Partition에서 메세지를 순차적으로 읽음
- Polling 구조를 가짐으로써 Consumer는 자신이 원하는 만큼의 메세지를 브로커에 요청
  - Broker로부터 메세지를 자동으로 푸시 받는 방식이 아닌 pull기반으로 Consumer가 poll() 메서드를 호출해 스스로 데이터를 가져오는 구조.
  - poll()로 가져온 레코드를 애플리케이션이 처리한 뒤, 오프셋을 커밋(auto/manual). 커밋된 오프셋은 다음 poll 시점의 기준점이 되어 중복, 유실 없는 메세지 처리 보장.
### (7) Consumer Group
- 같은 Group ID를 가진 Consumer들의 묶음
- 하나의 Partition은 같은 Group내의 하나의 Consumer에게만 할당되지만, 하나의 Consumer는 여러 Partition을 담당 할 수 있다.
- Consumer Group 내 Consumer 수를 늘려서 더 많은 Partition을 병렬처리하는 스케일 아웃방식을 활용할 수도 있다.
- Group 내 Consumer들이 자동으로 Partition을 분배하거나, Consumer 장애 시 Group 내 다른 Consumer가 해당 Partition을 리밸런싱하는 로드밸런싱이 적용된다.
- Consumer Group 내 Consumer들은 각자 특정 파티션의 소유권을 지니고 있어 컨슈머가 추가되거나 제외될경우, 새로운 파티션이 추가되는 경우 Consumer Group Coordinator가 리밸런싱을 수행한다.
- Consumer Group의 Consumer는 메세지를 Polling하거나 커밋할때 HeartBeat 메세지를 그룹 Coordinator에게 전달하고 HeartBeat내의 상태에 따라 Consumer의 상태(정상,장애발생 등)를 감지하고 장애를 감지하게 되면 리밸런싱을 수행한다.
## 3. Producer, Partition, Consumer 수 변화에 따른 데이터 흐름
```
Producer -> Broker (Topic, Partition) -> Consumer Group -> Consumer 
```
### (1) Producer 수 변화
- Producer 수 증가
  - 하나의 Topic/Partition으로 보내는 경우 단일 Partition에 부하가 집중되며 Throughput(처리량) 제한이 걸림.
  - Patition이 여러 개인 경우 Partitioner 전략에 따라 부하 분산처리 된다.
  - Producer 수가 많아질수록 Broker의 네트워크 I/O 및 Disk I/O에 부하가 증가한다.
  
`➡ 해결 :  Partition 수를 늘려 병목을 방지하거나 Partitioner 전략을 적절히 선택해 분산 조율`
### (2) Partition 수 변화
- Partition 수 증가
  - Throughput(처리량) 증가되며 더 많은 Consumer가 병렬로 처리 가능하다.
  - Broker 내에 Partition이 분산되어 리더-팔로워 복제 부하 분산이 가능하다.
  - 오버헤드가 증가하며 메타데이터 관리, 네트워크/디스크 리소스를 소비하게 된다.

`➡ 해결 : Parition수 = Consumer 수 이상으로 설정하게 되면 Consumer 병렬 처리가 극대화 되며, 너무 많으면 관리의 복잡성과 메타데이터 오버헤드를 고려`
### (3) Consumer 수 변화
- Consumer 수 < Partition 수
  - 일부 Consumer가 여러 Partition을 할당받아 처리하며 최대로 병렬화가 가능하다.
- Consumer 수 = Partition 수
  - 1:1 매핑으로 최적화 된 병렬처리가 가능하다.
- Consumer 수 > Partition 수
  - 일부 Consumer는 할당 받을 Partition이 없으므로 유휴상태에 이를 수 있다.

`➡ 설계 원칙 : Consumer 수는 Partition 수 이하로 맞추는 것을 기본으로, 스케일 아웃 시 Partition 수도 늘려줘야 효율적`

## 4. 결론
Kafka는 단순히 메세지를 송수신하는 시스템이 아니라 확장성, 병렬성, 내결합성을 핵심으로 하는 분산 스트리밍 플랫폼이다.
Product, Consumer, Partition의 수는 단순히 늘리거나 줄이는 것이 아니라 각 시스템의 부하, 데이터량, 처리 시간, 리소스 상황에 맞게 균형 있게 설계해야 한다.
특히 Partition 수는 병렬 처리 단위를 결정하고, Consumer 수는 Partition 수 이하로 설계 해야 자원낭비가 없다.
또 Producer는 Partition 분배 전략을 적절히 선택해야 데이터 skew현상(일부 파티션이 나머지 파티션에 비해 훨씬 더 많은 데이터를 가지고 있는 상태)을 방지할 수 있다.


