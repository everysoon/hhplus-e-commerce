# 선착순 쿠폰 및 상품 주문 성능 테스트 보고서

## 1. 목적

이커머스 플랫폼에서 높은 트래픽 하에, 선착순 쿠폰 발급 및 상품 주문 기능이 안정적으로 동작하는지를 검증하고
특히 동시성 이슈, 트랜잭션 일관성, 응답 시간, 시스템 리소스 소비량을 관찰함으로써 시스템의 병목 지점과 개선점을 도출하고자 한다.

## 2. 배경

- 선착순 쿠폰 발급은 유저 간 경쟁이 치열한 기능으로, 짧은 시간에 수천 건의 요청이 몰릴 수 있다.
- 상품 주문 기능은 재고 감소, 포인트 차감, 쿠폰 사용, 결제 등 복잡한 트랜잭션이 얽혀 있어 성능 저하 시 장애로 직결 될 수 있다.
- 실제 운영 환경에서 발생 가능한 부하를 시뮬레이션하여, 장애 발생 가능성과 병목 지점을 사전 파악하고자 한다.

## 3. 문제 정의

- 다수 사용자가 동시에 쿠폰을 요청할 경우, 재고 초과 발급, 중복 발급, 또는 트랜잭션 충돌로 인한 오류가 발생할 수 있다.
- 상품 주문 과정에서 JPA EntityManager 에러, DB 커넥션 풀 고갈, 비정상 롤백 현상이 간헐적으로 나타남.
- 해당 기능들은 서비스의 핵심 흐름이므로, p95, TPS, 오류율, 리소스 소비량을 종합적으로 분석하여 성능 병목을 해소해야 한다.

## 4. 테스트 설계

[테스트 도구] k6(v1.0.0)
[테스트 대상 API]

| 기능    | API                          | 설명                          |
|-------|------------------------------|-----------------------------|
| 쿠폰 발급 | `POST /api/coupons/{userId}` | 유저별 1회 발급, 선착순 제한           |
| 상품 주문 | `POST /api/orders`           | 재고 감소 + 결제 + 쿠폰 + 포인트 일괄 처리 |

[시나리오 구성]

```js
export const options = {
    vus: 100,
    duration: '60s',
    thresholds: {
        http_req_failed: ['rate<0.01'],
        http_req_duration: ['p(95)<500'],
    },
};
```

- vUsers (100명): 일반적인 피크 트래픽 가정을 기반으로 설정
- Duration: 60초 동안 지속적으로 요청
- Thresholds: 실패율 1% 이하 ,p95 응답시간 500ms 이하

[요청 구성]

- 유저는 src/resources/data.sql 로 초기화
- 쿠폰 발급: 테스트 쿠폰 생성 후 랜덤 유저 ID로 쿠폰 발급 요청
- 상품 주문: 테스트 상품 생성 후 (100개) 모든 유저 포인트 충전(10,000원), 그 후 랜덤 상품 ID와 랜덤 유저ID의 상품 주문 요청

## 5. 결과 분석

### 1) 상품 주문

| 항목                   | 값                   | 분석 요약                                |
|----------------------|---------------------|--------------------------------------|
| **총 요청 수**           | 6,274건              | 1분 동안 100 VU가 약 100 req/s 수준으로 요청 수행 |
| **요청 처리 속도 (RPS)**   | 100.22 req/s        | 실서비스 수준에서 현실적인 주문 처리 속도              |
| **성공률**              | 100%                | 모든 요청 성공 (http\_req\_failed = 0.00%) |
| **p95 응답 시간**        | 44.28ms             | 임계값 `p(95)<500ms` 여유 있게 만족           |
| **최대 응답 시간**         | 1.31초               | 일부 요청에서 비정상적으로 높은 지연 발생              |
| **평균 응답 시간**         | 29.04ms             | 주문 처리를 고려하면 준수한 편                    |
| **iteration 평균 시간**  | 966.01ms            | 실제 전체 처리 지연의 핵심 지표, 병목 발생 의심         |
| **iteration 최대 시간**  | 2.94초               | 최대 3초 가까이 대기, 락/큐 대기 지연 가능성 존재       |
| **p95 iteration 시간** | 1.88초               | 상위 5% 요청은 응답 이후 상당한 지연               |
| **VU 수**             | 평균 75\~100          | 정상적으로 부하 생성되었음                       |
| **데이터 수신/송신량**       | 수신 1.9MB / 송신 1.6MB | 요청당 payload 가벼움, 네트워크 병목 없음          |

✅ 성능 지표 분석

응답 자체는 대부분 50ms 미만으로 처리되어 API 성능 자체는 우수하고, p95 = 44ms, avg = 29ms로 HTTP Layer는 병목이 전혀 없음을 알 수 있다.
또한 checks_succeeded = 100%로 기능적 실패도 없음.

| 병목 원인 추정                     | 개선 방안 예시                                                                   |
|------------------------------|----------------------------------------------------------------------------|
| **DB 락 (ex. 재고 차감)**         | 재고 차감 로직을 `Optimistic Lock`, `Redis Lua Script`, 또는 `Token Bucket` 패턴으로 개선 |
| **쿠폰 / 포인트 동시 차감 처리**        | Saga 패턴 또는 이벤트 기반 CQRS로 분리 및 비동기 처리                                        |
| **메시지 큐 ACK/Timeout 지연**     | 메시지 소비자 성능 점검, `pre-fetch` 튜닝, 병렬 처리 수준 조정                                 |
| **단일 자원 경합 (ex. Redis Key)** | Redis 락 키를 사용자 단위 혹은 주문 UUID 단위로 나눠 락 경쟁 완화                                |

### 2) 선착순 쿠폰 발급

| 항목                  | 값           | 분석 요약                             |
|---------------------|-------------|-----------------------------------|
| **총 요청 수**          | 29,527건     | 약 1분 동안 100 VU가 지속적으로 요청 수행       |
| **요청 처리 속도 (RPS)**  | 486.4 req/s | 매우 높은 처리율, 병렬 처리 성능 우수            |
| **성공률**             | 100%        | 실패 없음 (http\_req\_failed = 0.00%) |
| **p95 응답 시간**       | 9.75ms      | 성능 임계 조건(`p(95)<500ms`) 충족        |
| **최대 응답 시간**        | 112.21ms    | 이상치 없이 안정적인 응답 분포                 |
| **평균 응답 시간**        | 5.09ms      | 일반적인 응답 시간 매우 우수                  |
| **iteration 평균 시간** | 204.66ms    | 응답 이후 처리 지연 가능성 내포                |
| **iteration 최대 시간** | 1.01초       | 일부 사용자 처리에 있어 병목 가능성 확인 필요        |
| **데이터 수신량**         | 5.7 MB      | 정상적인 네트워크 사용량                     |
| **데이터 송신량**         | 4.4 MB      | 쿠폰 요청-응답의 payload 크기 적절           |
| **VU 수**            | 100명 고정     | 테스트 중 스케일 변화 없이 유지됨               |

✅ 성능 지표 분석
모든 요청이 10ms 이내로 처리되며 p95 < 500ms 임계 조건도 여유롭게 만족하고, 최대 응답 시간도 112ms 수준으로, GC나 DB 지연 없이 서버와 네트워크 모두 안정적이다.
또한 성공률 100%, 즉 예외, 타임아웃, 실패 모두 발생하지 않았다.

## 6. 후속 조치 및 개선점

| 항목                                    | 조치                                                                                        |
|---------------------------------------|-------------------------------------------------------------------------------------------|
| `Could not open JPA EntityManager` 오류 | - `@Transactional` 메서드가 내부 호출로 인해 프록시 적용이 안되는 문제 해결<br>- 락 처리와 트랜잭션 분리 또는 외부 서비스 호출 방식 개선 |
| 커넥션 풀 고갈 방지                           | - HikariCP `maxPoolSize` 30 이상으로 조정<br>- DB 세션 모니터링 도입                                    |
| 응답시간 분포 개선                            | - `p99` 응답 개선 위해 일부 비동기 작업(Audit 로그, 이벤트 발행 등) 분리<br>- 트랜잭션 범위 최소화                        |
| 쿠폰 재고 일관성 확보                          | - Redisson 자료구조로 이루어진 쿠폰 발급 로직을 Redis Lua 스크립트 사용으로 전환                                    |
| k6 테스트 다각화                            | - `ramping-vus` 설정을 통해 트래픽 증가 시나리오로 추가 테스트 계획<br>- 단계별 vUser: 10 → 50 → 100 증가 시점 분석      |
| 모니터링 연동                               | Redis,GC,DB의 지표를 Prometheus + Grafana 등으로 지속 관찰                                           |
| 트래픽 증가 대비                             | VU 200~300까지 확장하여 붕괴 구간 탐색 필요                                                             |

## 7. 결론
- 선착순 쿠폰 API는 정상 동작 및 고성능 처리 가능 상태로 판단되지만, `iteration_duration`이 상대적으로 길어지는 부분은 잠재적인 비지니스 로직 후처리 병목 가능성이 있을 수 있음
  - VU 100 이상에서는 락 충돌/지연 여부에 대한 정밀한 분석 필요하다.
- 상품 주문은 `iteration_duration` 보았을때 재고 차감, 쿠폰 사용, 포인트 처리 등 복합 도메인 로직의 순차 처리 병목이나 캐시단의 락대기가 있을 수 있다.
  - p95 = 44ms, avg = 29ms로 HTTP Layer는 병목이 전혀 없음을 알 수 있다.

이번 테스트를 통해 선착순 쿠폰 발급과 상품 주문 기능 모두 대체로 안정적인 성능을 보였지만, 
일부 비정상 응답 시간과 `내부 EntityManager` 오류로 인해 커낵션 풀 고갈 방지를 위해 `HikariCP maxPoolSize`를 늘려주었으며
`p99`응답 개선을위해 일부 비동기 작업 분리 및 트랜잭션 범위를 최소화 하는 개선이 필요함을 알 수 있었다.
또, 선착순 쿠폰 발급의 경우 Redisson 자료구조를 통해 쿠폰 재고 차감을 진행하고 있었는데, 일관성 확보를 위해 `Lua Script`로 전환하였다.

지속적인 성능 테스트와 시스템 리소스 분석을 통해, 운영 환경에서도 신뢰성 높은 서비스가 가능하도록 구조 개선할 수 있는 경험이였다.


